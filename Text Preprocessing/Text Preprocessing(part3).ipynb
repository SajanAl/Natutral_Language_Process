{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abb6b3e",
   "metadata": {},
   "source": [
    "# Tokenization using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc922de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1='I have Ph.D in Cyber Security'\n",
    "sent2='I am programmer any queory mail! us khan@gmail.com'\n",
    "sent3='A 5km ride cost $10.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87fdbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8144cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(sent1)\n",
    "doc2=nlp(sent2)\n",
    "doc3=nlp(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa980be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "have\n",
      "Ph\n",
      ".\n",
      "D\n",
      "in\n",
      "Cyber\n",
      "Security\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6e959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "programmer\n",
      "any\n",
      "queory\n",
      "mail\n",
      "!\n",
      "us\n",
      "khan@gmail.com\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50b4113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "ride\n",
      "cost\n",
      "$\n",
      "10.5\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c77e94",
   "metadata": {},
   "source": [
    "# Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3702a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffeb0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1='playing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ac024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a561e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d257ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_word(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64f78dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=\"walking walked walks walk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef6f6bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_word(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40740166",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2='Mughal-e-Azam had the widest release of any Indian film up to that time, and patrons often queued all day for tickets. Released on 5 August 1960, it broke box office records in India and became the highest-grossing Indian film, a distinction it held for 15 years'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67e9297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mughal-e-Azam had the widest release of any Indian film up to that time, and patrons often queued all day for tickets. Released on 5 August 1960, it broke box office records in India and became the highest-grossing Indian film, a distinction it held for 15 years'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1535f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mughal-e-azam had the widest releas of ani indian film up to that time, and patron often queu all day for tickets. releas on 5 august 1960, it broke box offic record in india and becam the highest-gross indian film, a distinct it held for 15 year'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_word(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be44c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdb46fd2",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "124c9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f461c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WL=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f49ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3='He was running and eating at same time.He has bad habit of swimming after playing long hours in the sun.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46bf998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation=\".,:?!;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "241d1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3=nltk.word_tokenize(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db8cd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                lemma               \n",
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time.He             time.He             \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "sun                 sun                 \n"
     ]
    }
   ],
   "source": [
    "for word in text3:\n",
    "    if word in punctuation:\n",
    "        text3.remove(word)\n",
    "text3\n",
    "print(\"{0:20}{1:20}\".format('word','lemma'))\n",
    "for word in text3:\n",
    "    print(\"{0:20}{1:20}\".format(word,WL.lemmatize(word,pos='v')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34dbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c21cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
